---
title: 'TrackVLA: Embodied Visual Tracking in the Wild'
section: Poster
openreview: GIHDBntBu9
abstract: Embodied visual tracking is a fundamental skill in Embodied AI, enabling
  an agent to follow a specific target in dynamic environments using only egocentric
  vision. This task is inherently challenging as it requires both accurate target
  recognition and effective trajectory planning under conditions of severe occlusion
  and high scene dynamics. Existing approaches typically address this challenge through
  a modular separation of recognition and planning. In this work, we propose TrackVLA,
  a Vision-Language-Action (VLA) model that learns the synergy between object recognition
  and trajectory planning. Leveraging a shared LLM backbone, we employ a language
  modeling head for recognition and an anchor-based diffusion model for trajectory
  planning. To train TrackVLA, we construct an Embodied Visual Tracking Benchmark
  (EVT-Bench) and collect diverse difficulty levels of recognition samples, resulting
  in a dataset of 1.7 million samples. Through extensive experiments in both synthetic
  and real-world environments, TrackVLA demonstrates SOTA performance and strong generalizability.
  It significantly outperforms existing methods on public benchmarks in a zero-shot
  manner while remaining robust to high dynamics and occlusion in real-world scenarios
  at 10 FPS inference speed.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: wang25f
month: 0
tex_title: 'TrackVLA: Embodied Visual Tracking in the Wild'
firstpage: 4139
lastpage: 4164
page: 4139-4164
order: 4139
cycles: false
bibtex_author: Wang, Shaoan and Zhang, Jiazhao and Li, Minghan and Liu, Jiahang and
  Li, Anqi and Wu, Kui and Zhong, Fangwei and Yu, Junzhi and Zhang, Zhizheng and Wang,
  He
author:
- given: Shaoan
  family: Wang
- given: Jiazhao
  family: Zhang
- given: Minghan
  family: Li
- given: Jiahang
  family: Liu
- given: Anqi
  family: Li
- given: Kui
  family: Wu
- given: Fangwei
  family: Zhong
- given: Junzhi
  family: Yu
- given: Zhizheng
  family: Zhang
- given: He
  family: Wang
date: 2025-10-07
address:
container-title: Proceedings of The 9th Conference on Robot Learning
volume: '305'
genre: inproceedings
issued:
  date-parts:
  - 2025
  - 10
  - 7
pdf: https://raw.githubusercontent.com/mlresearch/v305/main/assets/wang25f/wang25f.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
