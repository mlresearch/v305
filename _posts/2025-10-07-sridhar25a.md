---
title: 'RICL:  Adding In-Context Adaptability to Pre-Trained Vision-Language-Action
  Models'
section: Poster
openreview: 6AASPlloSt
abstract: Multi-task “vision-language-action” (VLA) models have recently demonstrated
  increasing promise as generalist foundation models for robotics, achieving non-trivial
  performance out of the box on new tasks in new environments. However, for such models
  to be truly useful, an end user must have easy means to teach them to improve. For
  language and vision models, the emergent ability to perform in-context learning
  (ICL) has proven to be a versatile and highly useful interface to easily teach new
  tasks with no parameter finetuning. Unfortunately, VLAs pre-trained with imitation
  learning objectives do not naturally acquire ICL abilities. In this paper, we demonstrate
  that, with the right finetuning recipe and a small robot demonstration dataset,
  it is possible to inject in-context adaptability post hoc into such a VLA. After
  retraining for in-context learning (RICL), our system permits an end user to provide
  a small number (10-20) of demonstrations for a new task. RICL then fetches the most
  relevant portions of those demonstrations into the VLA context to exploit ICL, performing
  the new task and boosting task performance. We apply RICL to inject ICL into the
  $\pi_0$-FAST VLA, and show that it permits large in-context improvements for a variety
  of new manipulation tasks with only 20 demonstrations per task, without any parameter
  updates. When parameter updates on the target task demonstrations is possible, RICL
  finetuning further boosts performance. We release code and model weights for RICL-$\pi_0$-FAST
  alongside the paper to enable, for the first time, a simple in-context learning
  interface for new manipulation tasks
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: sridhar25a
month: 0
tex_title: 'RICL:  Adding In-Context Adaptability to Pre-Trained Vision-Language-Action
  Models'
firstpage: 5022
lastpage: 5038
page: 5022-5038
order: 5022
cycles: false
bibtex_author: Sridhar, Kaustubh and Dutta, Souradeep and Jayaraman, Dinesh and Lee,
  Insup
author:
- given: Kaustubh
  family: Sridhar
- given: Souradeep
  family: Dutta
- given: Dinesh
  family: Jayaraman
- given: Insup
  family: Lee
date: 2025-10-07
address:
container-title: Proceedings of The 8th Conference on Robot Learning
volume: '305'
genre: inproceedings
issued:
  date-parts:
  - 2025
  - 10
  - 7
pdf: https://raw.githubusercontent.com/mlresearch/v305/main/assets/sridhar25a/sridhar25a.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
