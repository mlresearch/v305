---
title: Elucidating the Design Space of Torque-aware Vision-Language-Action Models
section: Poster
openreview: HAmi1X11BO
abstract: Many robotic manipulation tasks require sensing and responding to force
  signals such as torque to assess whether the task has been successfully completed
  and to enable closed-loop control. However, current Vision-Language-Action (VLA)
  models lack the ability to integrate such subtle physical feedback. In this work,
  we explore Torque-aware VLA models, aiming to bridge this gap by systematically
  studying the design space for incorporating torque signals into existing VLA architectures.
  We identify and evaluate several strategies, leading to three key findings. First,
  introducing torque adapters into the decoder consistently outperforms inserting
  them into the encoder.  This is because torque signals align more closely with the
  decoderâ€™s input, and the decoder is more sensitive to variations in input. Second,
  torque history proves to be a critical signal. We find that the most effective way
  to incorporate it is by summarizing the entire history into a single token, as this
  preserves the original input pattern of the decoder. Third, inspired by joint prediction
  and planning paradigms in autonomous driving, we propose predicting torque as an
  auxiliary output, which further improves performance. This strategy encourages the
  model to build a physically grounded internal representation of interaction dynamics.
  Extensive quantitative and qualitative experiments across contact-rich manipulation
  benchmarks validate our findings. Code, models, and datasets will be released.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: zhang25k
month: 0
tex_title: Elucidating the Design Space of Torque-aware Vision-Language-Action Models
firstpage: 4019
lastpage: 4037
page: 4019-4037
order: 4019
cycles: false
bibtex_author: Zhang, Zongzheng and Xu, Haobo and Yang, Zhuo and Yue, Chenghao and
  Lin, Zehao and Gao, Huan-ang and Wang, Ziwei and Zhao, Hao
author:
- given: Zongzheng
  family: Zhang
- given: Haobo
  family: Xu
- given: Zhuo
  family: Yang
- given: Chenghao
  family: Yue
- given: Zehao
  family: Lin
- given: Huan-ang
  family: Gao
- given: Ziwei
  family: Wang
- given: Hao
  family: Zhao
date: 2025-10-07
address:
container-title: Proceedings of The 9th Conference on Robot Learning
volume: '305'
genre: inproceedings
issued:
  date-parts:
  - 2025
  - 10
  - 7
pdf: https://raw.githubusercontent.com/mlresearch/v305/main/assets/zhang25k/zhang25k.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
