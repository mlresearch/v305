---
title: 'SocialNav-SUB: Benchmarking VLMs for Scene Understanding in Social Robot Navigation'
section: Poster
openreview: xVDj9uq6K3
abstract: Robot navigation in dynamic, human-centered environments requires socially-compliant
  decisions grounded in robust scene understanding, including spatiotemporal awareness
  and the ability to interpret human intentions. Recent Vision-Language Models (VLMs)
  show exhibit promising capabilities such as object recognition, common-sense reasoning,
  and contextual understandingâ€”that align with the nuanced requirements of social
  robot navigation. However, it remains unclear whether VLMs can reliably perform
  the complex spatiotemporal reasoning and intent inference needed for safe and socially
  compliant robot navigation. In this paper, we introduce the Social Navigation Scene
  Understanding Benchmark (SocialNav-SUB), a Visual Question Answering (VQA) dataset
  and benchmark designed to evaluate VLMs for scene understanding in real-world social
  robot navigation scenarios. SocialNav-SUB provides a unified framework for evaluating
  VLMs against human and rule-based baselines across VQA tasks requiring spatial,
  spatiotemporal, and social reasoning in social robot navigation. Through experiments
  with state-of-the-art VLMs, we find that while the best-performing VLM achieves
  an encouraging probability of agreeing with human answers, it still underperforms
  a simpler rule-based approach and human consensus, indicating critical gaps in social
  scene understanding of current VLMs. Our benchmark sets the stage for further research
  on foundation models for social robot navigation, offering a framework to explore
  how VLMs can be tailored to meet real-world social robot navigation needs. We will
  open source the code and release the benchmark.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: munje25a
month: 0
tex_title: 'SocialNav-SUB: Benchmarking VLMs for Scene Understanding in Social Robot
  Navigation'
firstpage: 1120
lastpage: 1143
page: 1120-1143
order: 1120
cycles: false
bibtex_author: Munje, Michael Joseph and Tang, Chen and Liu, Shuijing and Hu, Zichao
  and Zhu, Yifeng and Cui, Jiaxun and Warnell, Garrett and Biswas, Joydeep and Stone,
  Peter
author:
- given: Michael Joseph
  family: Munje
- given: Chen
  family: Tang
- given: Shuijing
  family: Liu
- given: Zichao
  family: Hu
- given: Yifeng
  family: Zhu
- given: Jiaxun
  family: Cui
- given: Garrett
  family: Warnell
- given: Joydeep
  family: Biswas
- given: Peter
  family: Stone
date: 2025-10-07
address:
container-title: Proceedings of The 9th Conference on Robot Learning
volume: '305'
genre: inproceedings
issued:
  date-parts:
  - 2025
  - 10
  - 7
pdf: https://raw.githubusercontent.com/mlresearch/v305/main/assets/munje25a/munje25a.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
