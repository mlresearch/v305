---
title: 'DiWA: Diffusion Policy Adaptation with World Models'
section: Poster
openreview: NOQwVh1Gib
abstract: Fine-tuning diffusion policies with reinforcement learning (RL) presents
  significant challenges. The long denoising sequence for each action prediction impedes
  effective reward propagation. Additionally, standard RL methods require millions
  of physical interaction steps, making fine-tuning even more challenging. Prior work
  models the denoising steps in diffusion policies as a Markov Decision Process to
  adapt to RL policy updates, but its heavy reliance on environment interactions still
  leads to inefficiency. To bridge this gap, we introduce DiWA, a novel framework
  that leverages a world model for fine-tuning diffusion-based robotic skills entirely
  offline with reinforcement learning. Unlike model-free approaches that require millions
  of environment interactions to fine-tune a repertoire of robot skills, DiWA achieves
  effective adaptation using a world model trained once on a few hundred thousand
  offline play interactions. This results in dramatically improved sample efficiency,
  making the approach significantly more practical and safer for real-world robot
  learning. On the challenging CALVIN benchmark, DiWA improves performance across
  eight tasks using only offline adaptation, while requiring orders of magnitude fewer
  physical interactions than model-free baselines. To our knowledge, this is the first
  demonstration of fine-tuning diffusion policies for real-world robotic skills using
  an offline world model. We make the code publicly available at _redacted-for-review_.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: chandra25a
month: 0
tex_title: 'DiWA: Diffusion Policy Adaptation with World Models'
firstpage: 3378
lastpage: 3400
page: 3378-3400
order: 3378
cycles: false
bibtex_author: Chandra, Akshay L and Nematollahi, Iman and Huang, Chenguang and Welschehold,
  Tim and Burgard, Wolfram and Valada, Abhinav
author:
- given: Akshay L
  family: Chandra
- given: Iman
  family: Nematollahi
- given: Chenguang
  family: Huang
- given: Tim
  family: Welschehold
- given: Wolfram
  family: Burgard
- given: Abhinav
  family: Valada
date: 2025-10-07
address:
container-title: Proceedings of The 9th Conference on Robot Learning
volume: '305'
genre: inproceedings
issued:
  date-parts:
  - 2025
  - 10
  - 7
pdf: https://raw.githubusercontent.com/mlresearch/v305/main/assets/chandra25a/chandra25a.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
