---
title: 'DreamGen: Unlocking Generalization in Robot Learning through Video World Models'
section: Poster
openreview: 3CnxNqmklv
abstract: 'In this work, we unlock new capabilities in robot learning from neural
  trajectories, synthetic robot data generated from video world models. Our proposed
  recipe is simple, but powerful: we take the most recent state-of-the-art video generative
  models (world models), adapt them to the target robot embodiment, and generate new,
  synthetic robot data of the same task or even new behaviors. Since these video world
  models only generate videos, we explore two techniques of getting robot actions:
  extracting latent actions from a general-purpose latent action model and getting
  predicted actions from an inverse-dynamics model (IDM), giving flexibility across
  diverse scenarios. Our proposed approach unlocks behavior and environment generalization,
  allowing a humanoid robot to perform 20+ new behaviors in unseen environments while
  only collecting teleoperation data for pick and place in a single environment. By
  introducing a new world modeling benchmark, we demonstrate that stronger video world
  models directly correlate with improved downstream robot policy performance. This
  establishes a new scaling dimension beyond simply collecting additional teleoperation
  data, changing how we approach robot learning.'
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: jang25a
month: 0
tex_title: 'DreamGen: Unlocking Generalization in Robot Learning through Video World
  Models'
firstpage: 5170
lastpage: 5194
page: 5170-5194
order: 5170
cycles: false
bibtex_author: Jang, Joel and Ye, Seonghyeon and Lin, Zongyu and Xiang, Jiannan and
  Bjorck, Johan and Fang, Yu and Hu, Fengyuan and Huang, Spencer and Kundalia, Kaushil
  and Lin, Yen-Chen and Magne, Lo\"{i}c and Mandlekar, Ajay and Narayan, Avnish and
  Tan, You Liang and Wang, Guanzhi and Wang, Jing and Wang, Qi and Xu, Yinzhen and
  Zeng, Xiaohui and Zheng, Kaiyuan and Zheng, Ruijie and Liu, Ming-Yu and Zettlemoyer,
  Luke and Fox, Dieter and Kautz, Jan and Reed, Scott and Zhu, Yuke and Fan, Linxi
author:
- given: Joel
  family: Jang
- given: Seonghyeon
  family: Ye
- given: Zongyu
  family: Lin
- given: Jiannan
  family: Xiang
- given: Johan
  family: Bjorck
- given: Yu
  family: Fang
- given: Fengyuan
  family: Hu
- given: Spencer
  family: Huang
- given: Kaushil
  family: Kundalia
- given: Yen-Chen
  family: Lin
- given: Lo√Øc
  family: Magne
- given: Ajay
  family: Mandlekar
- given: Avnish
  family: Narayan
- given: You Liang
  family: Tan
- given: Guanzhi
  family: Wang
- given: Jing
  family: Wang
- given: Qi
  family: Wang
- given: Yinzhen
  family: Xu
- given: Xiaohui
  family: Zeng
- given: Kaiyuan
  family: Zheng
- given: Ruijie
  family: Zheng
- given: Ming-Yu
  family: Liu
- given: Luke
  family: Zettlemoyer
- given: Dieter
  family: Fox
- given: Jan
  family: Kautz
- given: Scott
  family: Reed
- given: Yuke
  family: Zhu
- given: Linxi
  family: Fan
date: 2025-10-07
address:
container-title: Proceedings of The 9th Conference on Robot Learning
volume: '305'
genre: inproceedings
issued:
  date-parts:
  - 2025
  - 10
  - 7
pdf: https://raw.githubusercontent.com/mlresearch/v305/main/assets/jang25a/jang25a.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
