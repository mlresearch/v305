---
title: 'LaVA-Man: Learning Visual Action Representations for Robot Manipulation'
section: Poster
openreview: 1D6XYy6ofW
abstract: 'Visual-textual understanding is essential for language-guided robot manipulation.
  Recent works leverage pre-trained vision-language models to measure the similarity
  between encoded visual observations and textual instructions, and then train a model
  to map this similarity to robot actions. However, this two-step approach limits
  the model to capture the relationship between visual observations and textual instructions,
  leading to reduced precision in manipulation tasks. We propose to learn visual-textual
  associations through a self-supervised pretext task: reconstructing a masked goal
  image conditioned on an input image and textual instructions. This formulation allows
  the model to learn visual-action representations without robot action supervision.
  The learned representations can then be fine-tuned for manipulation tasks with only
  a few demonstrations. We also introduce the \textit{Omni-Object Pick-and-Place}
  dataset, which consists of annotated robot tabletop manipulation episodes, including
  180 object classes and 3,200 instances with corresponding textual instructions.
  This dataset enables the model to acquire diverse object priors and allows for a
  more comprehensive evaluation of its generalisation capability across object instances.
  Experimental results on the five benchmarks, including both simulated and real-robot
  validations, demonstrate that our method outperforms prior art.'
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: zhu25b
month: 0
tex_title: 'LaVA-Man: Learning Visual Action Representations for Robot Manipulation'
firstpage: 5506
lastpage: 5525
page: 5506-5525
order: 5506
cycles: false
bibtex_author: Zhu, Chaoran and Wang, Hengyi and Pang, Yik Lung and Oh, Changjae
author:
- given: Chaoran
  family: Zhu
- given: Hengyi
  family: Wang
- given: Yik Lung
  family: Pang
- given: Changjae
  family: Oh
date: 2025-10-07
address:
container-title: Proceedings of The 8th Conference on Robot Learning
volume: '305'
genre: inproceedings
issued:
  date-parts:
  - 2025
  - 10
  - 7
pdf: https://raw.githubusercontent.com/mlresearch/v305/main/assets/zhu25b/zhu25b.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
